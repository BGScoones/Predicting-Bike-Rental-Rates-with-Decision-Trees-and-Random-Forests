{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In this project, we'll be working with a dataset taken from the Univeristy of California, Irvine's website on bike rentals in the city of Washington, D.C. Each row of the dataset contains information for a single hour, and there are 17,380 rows in total. We'll be using the data to try and predict the total number of bikes people rented in a given hour, and we'll do this with a few different machine learning models.\n",
    "\n",
    "Information on the dataset can be found [here](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset).\n",
    "\n",
    "Let's read in the data and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rentals = pd.read_csv(\"bike_rental_hour.csv\")\n",
    "rentals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff970e0deb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "rentals[\"cnt\"].hist()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instant       0.278379\n",
      "season        0.178056\n",
      "yr            0.250495\n",
      "mnth          0.120638\n",
      "hr            0.394071\n",
      "holiday      -0.030927\n",
      "weekday       0.026900\n",
      "workingday    0.030284\n",
      "weathersit   -0.142426\n",
      "temp          0.404772\n",
      "atemp         0.400929\n",
      "hum          -0.322911\n",
      "windspeed     0.093234\n",
      "casual        0.694564\n",
      "registered    0.972151\n",
      "cnt           1.000000\n",
      "Name: cnt, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hr            0.394071\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hum          -0.322911\n",
       "casual        0.694564\n",
       "registered    0.972151\n",
       "cnt           1.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs = rentals.corr()\n",
    "cnt_corrs = corrs[\"cnt\"]\n",
    "str_corrs = cnt_corrs[abs(cnt_corrs) > 0.3]\n",
    "print(cnt_corrs)\n",
    "str_corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Discussion\n",
    "\n",
    "The number of bike rentals in an hour seems to follow a simple geometric distribution, with between 0 and 100 bikes being rented for around 40% of the hours, and between 100 and 200 bikes for another 20% of the hours.\n",
    "\n",
    "The features that correlate most strongly with bike rentals are the hour of day, the temperature, the \"feeling temperature\", the humidity, and the casual and registered users. Casual and registered users, though, while technically correlated with the number of bikes that are rented, are not causally related, but rather merely count what portion of the bikes rented are rented by causal users or registered users, so we can ignore these columns for our purposes.\n",
    "\n",
    "Other features that might be relevant to the number of bike rentals are the year, month, and weather situation. The weather situation is recorded on a numerical ordinal scale, which means that, while the correlation value we have for the column is not ideal, as the scale itself does not indicate degrees of difference, it does still tell us that, as the weather becomes more severe (1 is clear, 4 is heavy rain, ice, snow, etc.) fewer bikes tend to be rented.\n",
    "\n",
    "### Cleaning the Data\n",
    "\n",
    "The main things we want to do here are remove irrelevant columns, to make data processing quicker, and alter some columns so that the information they contain is easier to deal with. We'll remove the causal and registered columns for the first reason. We'll make the information in the hours column more coarsely grained so that our models aren't overfitting to specific hours.\n",
    "\n",
    "At present, our data is fine-grained with respect to time, but we don't need it to be this precise. Instead, we can group the hours into larger portions based on the type of activity we expect in those hours. For example, the hours between 6 and 12 are likely to be fairly similar with people travelling to work. The hours between 12 and 6pm likewise, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "      <th>time_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  cnt  time_label  \n",
       "0           1  0.24  0.2879  0.81        0.0   16           4  \n",
       "1           1  0.22  0.2727  0.80        0.0   40           4  \n",
       "2           1  0.22  0.2727  0.80        0.0   32           4  \n",
       "3           1  0.24  0.2879  0.75        0.0   13           4  \n",
       "4           1  0.24  0.2879  0.75        0.0    1           4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rentals = rentals.drop([\"casual\", \"registered\"], axis = 1)\n",
    "\n",
    "def assign_label(hour):\n",
    "    if hour <= 6 :\n",
    "        return 4\n",
    "    if hour <= 12 and hour > 6:\n",
    "        return 1\n",
    "    if hour <= 18 and hour > 12:\n",
    "        return 2\n",
    "    if hour <= 24 and hour > 18:\n",
    "        return 3\n",
    "    \n",
    "rentals[\"time_label\"] = rentals[\"hr\"].apply(assign_label)\n",
    "rentals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split our data into train and test partitions. Our dataset is currently sorted, so to make sure our train and test sets are random, we'll select our training set with the pd.sample method and then assign the rest to our test set.\n",
    "\n",
    "To evaluate the accuracy of our models, we'll use MAE. This is because we'll be comparing the accuracy of models directly, and the cnt column measures a discrete, interval value. MAE will tell us exactly how many our predictions of the number of bikes rented are off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = rentals.sample(frac = 0.8)\n",
    "test = rentals.loc[~rentals.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Predictions\n",
    "\n",
    "We'll start off by doing a linear regression analysis. Linear regression tends to work better when our features are linearly correlated with our target, and when the features are independent from one another.\n",
    "\n",
    "Not all of the features in our dataset are independent (temp and atemp are directly linked, and working day is derived from holiday and weekday), but most are, and so linear regression should do fine in this regard. It's difficult to predict whether the relationship between the features and the number of rentals is linear or not, but in general it seems likely that they are.\n",
    "\n",
    "We'll remove working day from our list of features, as the information it contains is already present in the weekday and holiday columns, but having these columns themselves will help us identify whether holidays or day of the week individually are good predictors of rental count. We'll also get rid of dteday, instant, cnt, and hr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(rentals)\n",
    "features.remove(\"workingday\")\n",
    "features.remove(\"instant\")\n",
    "features.remove(\"dteday\")\n",
    "features.remove(\"cnt\")\n",
    "features.remove(\"hr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train[features], train[\"cnt\"])\n",
    "train_pred = lr.predict(train[features])\n",
    "test_pred = lr.predict(test[features])\n",
    "train_mae = mean_absolute_error(train_pred, train[\"cnt\"])\n",
    "test_mae = mean_absolute_error(test_pred, test[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.47653455346907 98.76776472139447\n"
     ]
    }
   ],
   "source": [
    "print(train_mae, test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps unsurprisingly, the error is high. As we saw above, of the rows in the dataset, 40% had a rental count of between 0 and 100. With an MAE of almost 100, our average prediction is 100 off the actual value. As a proportion of the number of bikes that are actually being rented, this is very high.\n",
    "\n",
    "This may be due to the fact that we've trained our model largely indiscriminately on the features in the dataset, rather than selecting specific features that are likely to be better correlated with rental count. We therefore have low bias, but high variance.\n",
    "\n",
    "However, it is possible that a linear regression model is not the best model for our dataset. Let's now try a decision tree to see how it compares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Predictions\n",
    "\n",
    "We'll use a decision tree to see if it does any better. The predictive accuracy of the decision tree will likely already have been helped by making the hours of our dataset more coarse-grained, which will hopefully somewhat prevent overfitting. However, overfitting is a typical issue with decision tree models, and so it is likely it will still be observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(train[features], train[\"cnt\"])\n",
    "train_pred = dtr.predict(train[features])\n",
    "test_pred = dtr.predict(test[features])\n",
    "train_mae = mean_absolute_error(train_pred, train[\"cnt\"])\n",
    "test_mae = mean_absolute_error(test_pred, test[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6019324366443692 90.8487725354814\n"
     ]
    }
   ],
   "source": [
    "print(train_mae, test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, our initial model is massively overfitted to the training dataset. Despite this, however, the predictions it made on the test set are still notably better than those made by the linear regression model we used above.\n",
    "\n",
    "We can try and reduce the overfitting of our model, and hopefully improve the accuracy of its predictions, by altering some of the parameters of the DecisionTreeRegressor class. One such parameter is min_samples_split. This sets the minimum number of rows a node should have before it can be split. Nodes with fewer rows than the specified number will not be split, but will instead form a leaf. This should reduce overfitting because rows which buck the general trend will not be isolated as their own leaves, but will instead belong to a larger leaf which, on average, exhibits the general trend. When sorting through rows to make predictions, no rows will be sorted into the leaves which represent outliers, and so the prediction for that row will be based instead on the general trend for similar rows, rather than on the value for the outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_dtr(train, test, features, min_samples):\n",
    "    dtr = DecisionTreeRegressor(min_samples_split = min_samples)\n",
    "    dtr.fit(train[features], train[\"cnt\"])\n",
    "    train_pred = dtr.predict(train[features])\n",
    "    test_pred = dtr.predict(test[features])\n",
    "    train_mae = mean_absolute_error(train_pred, train[\"cnt\"])\n",
    "    test_mae = mean_absolute_error(test_pred, test[\"cnt\"])\n",
    "    train_maes.append(train_mae)\n",
    "    test_maes.append(test_mae)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_samples = [2, 5, 10, 20, 30, 50]\n",
    "\n",
    "train_maes = []\n",
    "test_maes = []\n",
    "\n",
    "for sample in min_samples:\n",
    "    run_dtr(train, test, features, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.6019324366443692, 90.39058304564634),\n",
       " (25.964863698482343, 87.22039221327195),\n",
       " (42.33290982076496, 82.85458518274974),\n",
       " (54.45779192115858, 78.98491481687815),\n",
       " (59.74605218335536, 77.67801230766959),\n",
       " (65.96717536981632, 77.94002648723084)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maes = zip(train_maes, test_maes)\n",
    "list(maes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as we increase the min_samples_split parameter, the error for the model decreases, and the degree of overfitting is also reduced. For our final min_samples_split value of 50, we had fairly similar errors for our training predictions and test predictions, indicating less overfitting (although the model is undoubtedly still overfit)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Predictions\n",
    "\n",
    "One of the best ways to reduce the overfitting we've observed in both of our above models is with a random forest.\n",
    "\n",
    "A random forest is an ensemble of decision trees (an ensemble being a collection of items which are considered or analyzed together). That is, our random forest consists of many different decision tree models. When we use a random forest to make a prediction, we make a prediction using every decision tree model in the ensemble, and from this set of predictions, we average or aggregate the result in some way to make our final prediction.\n",
    "\n",
    "A random forest is good for reducing overfitting because it better hones in on the signal that is our predicted value. Every decision tree in the random forest will be slightly different and will pick up on small changes in the data differently. Some of the decision trees will handle these small changes well, and they will inform their predictions positively. Others, however, will handle them poorly, and they'll lead a decline in their predictive accuracy. With a full forest of decision trees, the goal is to average out the negative effects, and single in on the prediction that will be the most accurate.\n",
    "\n",
    "Let's see how using a random forest affects our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def run_rfr(train, test, features, trees, min_samples):\n",
    "    rfr = RandomForestRegressor(n_estimators = trees, min_samples_split = min_samples)\n",
    "    rfr.fit(train[features], train[\"cnt\"])\n",
    "    train_pred = rfr.predict(train[features])\n",
    "    test_pred = rfr.predict(test[features])\n",
    "    train_mae = mean_absolute_error(train_pred, train[\"cnt\"])\n",
    "    test_mae = mean_absolute_error(test_pred, test[\"cnt\"])\n",
    "    train_maes.append(train_mae)\n",
    "    test_maes.append(test_mae)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = [2, 5, 10, 20, 30, 50]\n",
    "trees = [5, 10, 20, 50]\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "combs = product(min_samples, trees)\n",
    "combinations = []\n",
    "for item in combs:\n",
    "    item = list(item)\n",
    "    combinations.append(item)\n",
    "    \n",
    "train_maes = []\n",
    "test_maes = []\n",
    "\n",
    "for combination in combinations:\n",
    "    run_rfr(train, test, features, trees = combination[1], min_samples = combination[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31.218573963139164, 75.94314882550643),\n",
       " (29.946315235409138, 72.93257387391091),\n",
       " (28.46469367836564, 72.50561854987488),\n",
       " (27.68218342755968, 71.63924947942353),\n",
       " (40.42029560687621, 75.3874596085413),\n",
       " (38.03311036901594, 73.72057541973753),\n",
       " (37.08240106425498, 72.11592754455779),\n",
       " (36.57857908825514, 71.33318389982274),\n",
       " (49.61464813618825, 74.10688073153048),\n",
       " (48.388736802026415, 73.37843383739323),\n",
       " (47.65327947862221, 72.77107398861084),\n",
       " (46.90474343159617, 72.19323753217468),\n",
       " (58.52539535950215, 74.70423456263148),\n",
       " (57.53207043764489, 73.3847998772585),\n",
       " (56.700288027029174, 72.85136015096366),\n",
       " (56.44686445656547, 72.82539909498456),\n",
       " (62.781429327605075, 74.81360472547642),\n",
       " (62.03415594984014, 74.74313889248326),\n",
       " (61.48527277884559, 73.59387678643792),\n",
       " (61.37852102273559, 73.65527087524136),\n",
       " (67.68992837777816, 75.80529894683475),\n",
       " (66.80397806715311, 75.38404689142702),\n",
       " (66.65101443640637, 75.0259237213836),\n",
       " (66.55025429465441, 74.83333077854465)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = zip(train_maes, test_maes)\n",
    "list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In all cases for our random forest, as we increased the number of trees, our predictions got more accurate. However, the most accurate model with regards to test MAE was that which used min_samples = 5, and trees = 50. After this point, as min_samples increased, the accuracy of the test MAE decreased.\n",
    "\n",
    "Again, however, we should note that as min_samples increased, the difference between the training and test MAEs decreased, indicating that as min_samples increased overfitting also decreased.\n",
    "\n",
    "In all cases, however, if we compare our random forest predictions with those of our decision tree predictions, the predictions of the random forest models are better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
